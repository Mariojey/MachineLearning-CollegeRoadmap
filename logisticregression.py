# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K8x3Z5SBKMlXkZU7cGujTB4UPgKR59-w

Dataset: Smarket from ISLP
"""

from ISLP import load_data
from ISLP.models import (ModelSpec as MS, summarize)

"""All necessary libraries"""

import numpy as np
import pandas as pd
from matplotlib.pyplot import subplots

"""Import regression library"""

import statsmodels.api as sm

from ISLP import confusion_table
from ISLP.models import contrast

from sklearn.discriminant_analysis import (LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA)

from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

"""Loading data"""

Smarket = load_data('Smarket')

Smarket.head()

Smarket.plot(y='Volume')

"""Logistic Regression

sm.GLM() function fits generalized linear models, class of models which includes logistic regression models. Or we can use sm.Logit() method which fit a model directly. Syntax GLM is simply the same as OLS(), but we need to remember that we must pass params family
"""

allvars = Smarket.columns.drop(['Today', 'Direction','Year'])
design = MS(allvars)

X = design.fit_transform(Smarket)
y = Smarket.Direction == "Up"

glm = sm.GLM(y, X, family=sm.families.Binomial())

results = glm.fit()
summarize(results)

results.params

results.pvalues

probs = results.predict()
probs[:10]

labels = np.array(['Down']*1250)
labels[probs>0.5] = "Up"

confusion_table(labels, Smarket.Direction)

(507+145)/1250, np.mean(labels == Smarket.Direction)